{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP6714 18s2 Project\n",
    "\n",
    "# Stage 2: Modify a baseline model of hyponymy classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deadline and Late Penalty\n",
    "\n",
    "The project deadline is **23:59 26 Oct 2018 (Fri)**. \n",
    "\n",
    "Late penalty is -10% each day for the first three days, and then -20% each day afterwards. \n",
    "\n",
    "\n",
    "## Objective\n",
    "As explained in stage 1, in this project you need to build a system that can extract [hyponym and hypernym](https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy) relations from a sentence. \n",
    "\n",
    "Now, we provide you with the baseline model and you are required to **modifiy** it according to the specification given below. The baseline model follows the achitecture introduced in the **Stage 1 spec**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run (and understand) the baseline model\n",
    "In order to play with the baseline model, you just need to execute the following command:\n",
    "```\n",
    "python train.py\n",
    "```\n",
    "where\n",
    "* You can modify `config.py` to change hyper-parameters.\n",
    "* You can modify `randomness.py` to manipulate the randomness (e.g., change random seed).\n",
    "* If you want to test the performance of the trained model, then you need to implement a test method by yourself.\n",
    "\n",
    "We suggest that you read and understand the baseline model first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your tasks\n",
    "You need to complete your implementation in the file `todo.py`. You are required to implemnet the following three methods.\n",
    "* `get_char_sequence()`\n",
    "* `new_LSTMCell()`\n",
    "* `evaluate()`\n",
    "\n",
    "The modified `todo.py` will be submitted for evaluation.\n",
    "\n",
    "**NOTE**: you can modify `config.py` to enable the above modifications in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implement `evaluate()` (30%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are required to implement the `evaluate()` method in `todo.py`. This method computes the F1 score of the given predicted tags and golden tags (i.e., ground truth). \n",
    "\n",
    "The **input** arguments of `evaluate()` are:\n",
    "* `golden_list` is a list of list of tags, which stores the golden tags.\n",
    "* `predict_list` is a list of list of tags, which stores the predicted tags.\n",
    "\n",
    "The method should **return** the F1 score based on `golden_list` and `predict_list`. In this project, we only consider the phrase level matching for *TAR* and *HYP* (*O* is not considered). Two entities are matched when both the boundaries and the tags are the same. \n",
    "\n",
    "For example, given\n",
    "```\n",
    "golden_list = [['B-TAR', 'I-TAR', 'O', 'B-HYP'], ['B-TAR', 'O', 'O', 'B-HYP']]\n",
    "predict_list = [['B-TAR', 'O', 'O', 'O'], ['B-TAR', 'O', 'B-HYP', 'I-HYP']]\n",
    "```\n",
    "* The first *TAR* in `golden_list` does not match with `predict_list`, as the boundary is not incorrect (e.g., `predict_list[0][1]` is `O`, which should be `I-TAR` for a correct matching).\n",
    "* The second *TAR* in `golden_list` matches with the second *TAR* in `predict_list`, as both the boundary and the tag are the same.\n",
    "* The number of *false positives* in the above example is 2, the number of *false negative* in the above example is 3, and the number of *true positive* is 1. Therefore, the F1 should be 0.286.\n",
    "\n",
    "**NOTE**:\n",
    "* The length of the two lists are the same, and length of the $i$-th instance in both lists are the same as well. Which means that you do not need to handle the alignment issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement `new_LSTMCell()` (30%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are required to implement a new version of the LSTM Cell (i.e., `new_LSTMCell()` in `todo.py`), which has a different logic of controlling the input gate.\n",
    "\n",
    "Instead of separately deciding what to forget and what we should add new information to, we make those decisions together. We only forget when weâ€™re going to input something in its place. We only input new values to the state when we forget something older.\n",
    "\n",
    "Specifically, before the modification, we have\n",
    "$$\n",
    "C_t = f_t * C_{t-1} + i_t * \\tilde{C_t}\n",
    "$$\n",
    "where $i_t$ is the activation vector of the input gate, and $f_t$ is the activation vector of the forget gate.\n",
    "\n",
    "By letting $i_t = 1 - f_t$, after the modification, we have\n",
    "$$\n",
    "C_t = f_t * C_{t-1} + (1 - f_t) * \\tilde{C_t}\n",
    "$$\n",
    "\n",
    "**NOTE:**\n",
    "* Your implementation should base on the original implementation (i.e., `torch.nn._functions.rnn.LSTMCell()`). Please read and understand it first.\n",
    "* Please do not change the input arguments of the method, i.e., \n",
    "```\n",
    "    def new_LSTMCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):\n",
    "```\n",
    "* We do not use GPU in this project, therefore, you do not need to change the following part (or simply remove them from your implementation), as input.is_cuda is always false:\n",
    "```\n",
    "    if input.is_cuda:\n",
    "        igates = F.linear(input, w_ih)\n",
    "        hgates = F.linear(hidden[0], w_hh)\n",
    "        state = fusedBackend.LSTMFused.apply\n",
    "        return state(igates, hgates, hidden[1]) if b_ih is None else state(igates, hgates, hidden[1], b_ih, b_hh)\n",
    "```\n",
    "* In order to avoid unnecessary errors during the project evaluation, please do not change the following three lines from the original implementation, although you may not use all the vaiables.\n",
    "```\n",
    "hx, cx = hidden\n",
    "gates = F.linear(input, w_ih, b_ih) + F.linear(hx, w_hh, b_hh)\n",
    "ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Implement `get_char_sequence()` (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are required to implement a BiLSTM layer for Character embedding (i.e., *char BiLSTM* in the following figure). The output of the char BiLSTM will be concatenated with word embedding from the data preprocessing to form the new input tensor. \n",
    "\n",
    "The new architecture will be like\n",
    "\n",
    "<img src=\"workflow.png\" width=\"45%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specifically, you need to implement the method `get_char_sequence()` in `todo.py`.<br>\n",
    "Its input arguments are:\n",
    "* `model` is an object of `sequence_labeling`, refer to line 49 of `model.py` to see how the method is called\n",
    "* `batch_char_index_matrices` is a tensor that can be viewed as a list of matrices storing char_ids, where each matrix corresponds to a sentence, each sentence corresponds to a list of words, and each word corresponds to a list of char_ids. \n",
    "* `batch_word_len_lists` is tensor that can be viewed as a list of lists. Where each list corresponds to a sentence, and stores the length of each word.\n",
    "\n",
    "The **output** dimension of the char BiLSTM is defined in `config.py` (i.e., `char_lstm_output_dim`)\n",
    "\n",
    "Hint: \n",
    "* We suggest you to read and understand the code in `model.py` first, especially the part of BiLSTM layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of the *char BiLSTM* layer is as below:\n",
    "<img src=\"charlstm.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are required to experiment your implementation and submit a report (named as `report.pdf`). The report should at least answer the following questions (you should answer them in different sections)\n",
    "\n",
    "* How do you implement `evaluate()`?\n",
    "* How does Modification 1 (i.e., storing model with best performance on the development set) affect the performance?\n",
    "* How do you implement `new_LSTMCell()`?\n",
    "* How does Modification 2 (i.e., re-implemented LSTM cell) affect the performance?\n",
    "* How do you implement `get_char_sequence()`?\n",
    "* How does Modification 3 (i.e., adding Char BiLSTM layer) affect the performance?\n",
    "\n",
    "You may need to implement a test function in order to test the performance of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to submit the following 2 files:\n",
    "1. `todo.py`\n",
    "2. `report.pdf`\n",
    "\n",
    "**NOTE**:\n",
    "The detail of how to submit your files will be announced later in the Piazza forum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing the project, you are welcomed to implement your own model (rather than modifying the given baseline implementation). If you choose to do so, please make sure that\n",
    "\n",
    "1. your implementation outperforms the baseline model by a large margin (the number will be announced later) on the given test set.\n",
    "2. you report the implementation details as a short report.\n",
    "\n",
    "There are some research papers for your reference:\n",
    "* [Long Short-Term Memory as a Dynamically Computed Element-wise Weighted Sum - ACL18](http://www.aclweb.org/anthology/P18-2116)\n",
    "* [Deep contextualized word representations - NAACL18](https://arxiv.org/abs/1802.05365)\n",
    "* [Fast and accurate entity recognition with iterated dilated convolutions - EMNLP17](http://aclweb.org/anthology/D17-1283)\n",
    "* [Neural models for sequence chunking - AAAI17](https://arxiv.org/abs/1701.04027)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission of Bonus Part\n",
    "\n",
    "If you choose to do a bonus part, you need to submit a `.zip` file which contains:\n",
    "1. the code of your model\n",
    "2. the report (as a pdf file)\n",
    "\n",
    "The report should contain at least the following two parts:\n",
    "1. The implementation detail of your model (e.g., what are the differences between your model and the baseline model).\n",
    "2. The instruction of how to execute your code.\n",
    "\n",
    "**NOTE**:\n",
    "* It is unnecessary to include the training, development and testing files in your submission.\n",
    "* The detail of the bonus part will be announced later in the Piazza forum."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
